# -*- coding: utf-8 -*-
"""TrOCR (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Kumari-Aayushi/OCR_Project/blob/main/TrOCR%20(1).ipynb
"""

import zipfile
import os

zip_path = "/content/handwritten500.zip"
extract_path = "/content/handwritten500"

# Ensure clean extraction directory
if not os.path.exists(extract_path):
    os.makedirs(extract_path)

# Extract
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("‚úÖ Successfully unzipped to:", extract_path)

import os

for root, dirs, files in os.walk(extract_path):
    print(f"{root} - {len(files)} files")
    for f in files[:5]:  # Show first 5 files in each folder
        print(f"  - {f}")

"""# Prediction of Handwritten Text Image Using TrOCR  """

# ‚úÖ Step 1: Install Required Libraries (if not done yet)
!pip install -U -q transformers torch torchvision torchaudio

# ‚úÖ Step 2: Imports
import os
import glob
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# ‚úÖ Step 3: Define Paths
image_dir = "/content/handwritten500/handwritten500/english_lines"

# ‚úÖ Step 4: Load TrOCR Model
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ‚úÖ Step 5: Prediction Function
def predict_text(image_path):
    image = Image.open(image_path).convert("RGB")
    inputs = processor(images=image, return_tensors="pt").to(device)
    generated_ids = model.generate(inputs.pixel_values)
    pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return pred_text.strip()

# ‚úÖ Step 6: Get First 5 Image Paths
image_paths = sorted(glob.glob(os.path.join(image_dir, "*.png")))[:5]

# ‚úÖ Step 7: Predict and Print Text for Each Image
print("üñºÔ∏è  OCR Predictions on First 5 English Handwritten Line Images:\n")
for path in image_paths:
    pred = predict_text(path)
    print(f"{os.path.basename(path)} ‚Üí {pred}")

# ‚úÖ Step 1: Install Required Libraries (if not already installed)
!pip install -U -q transformers torch torchvision torchaudio

# ‚úÖ Step 2: Imports
import os
import glob
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# ‚úÖ Step 3: Define Paths
image_dir = "/content/handwritten500/handwritten500/english_lines"

# ‚úÖ Step 4: Load TrOCR Model and Processor
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ‚úÖ Step 5: Prediction Function
def predict_text(image_path):
    try:
        image = Image.open(image_path).convert("RGB")
        inputs = processor(images=image, return_tensors="pt").to(device)
        generated_ids = model.generate(inputs.pixel_values)
        pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        return pred_text.strip()
    except Exception as e:
        return f"[ERROR] {e}"

# ‚úÖ Step 6: Get First 100 Image Paths
image_paths = sorted(glob.glob(os.path.join(image_dir, "*.png")))[:100]

# ‚úÖ Step 7: Predict and Print Text for Each Image
print("üîç OCR Predictions on First 100 English Handwritten Line Images:\n")
for idx, path in enumerate(image_paths, 1):
    pred = predict_text(path)
    print(f"{idx:03d}. {os.path.basename(path)} ‚Üí {pred}")

"""Accuracy of all Hanwritten English Line Images Using TrOCR"""

# ‚úÖ Step 1: Install Required Libraries
!pip install -q transformers torch torchvision torchaudio jiwer opencv-python

# ‚úÖ Step 2: Import Libraries
import os
import glob
import cv2
import numpy as np
from PIL import Image
import torch
from tqdm import tqdm
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from jiwer import cer, wer

# ‚úÖ Step 3: Set Dataset Paths
image_dir = "/content/handwritten500/handwritten500/english_lines"
gt_dir = os.path.join(image_dir, "ground_truth")

# ‚úÖ Step 4: Load Improved TrOCR Model (LARGE)
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-large-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-large-handwritten")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ‚úÖ Step 5: Enhanced Preprocessing Function (OpenCV)
def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    # Resize for consistency
    h, w = img.shape
    if h < 32:
        scale = 32 / h
        img = cv2.resize(img, (int(w * scale), 32), interpolation=cv2.INTER_AREA)

    # Binarize using adaptive threshold
    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                cv2.THRESH_BINARY, 11, 2)

    # Convert to 3-channel RGB for model
    img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    return Image.fromarray(img_rgb)

# ‚úÖ Step 6: Prediction Function
def predict_text(image_path):
    try:
        image = preprocess_image(image_path)
        inputs = processor(images=image, return_tensors="pt").to(device)
        generated_ids = model.generate(inputs.pixel_values)
        pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

        # Clean output
        return pred_text.strip().replace("\n", " ").replace("  ", " ")
    except Exception as e:
        return f"[ERROR] {e}"

# ‚úÖ Step 7: Run Evaluation on All 270 Images
image_paths = sorted(glob.glob(os.path.join(image_dir, "*.png")))
predictions, ground_truths = [], []

print("üìä Evaluating with Improved Accuracy...\n")
for path in tqdm(image_paths, desc="üîç Predicting"):
    base_name = os.path.basename(path).replace(".png", ".txt")
    gt_path = os.path.join(gt_dir, base_name)

    if not os.path.exists(gt_path):
        print(f"‚ö†Ô∏è Missing GT for {base_name}, skipping.")
        continue

    # Ground truth
    with open(gt_path, "r", encoding="utf-8") as f:
        gt_text = f.read().strip().lower()

    # Prediction
    pred_text = predict_text(path).lower()

    ground_truths.append(gt_text)
    predictions.append(pred_text)

# ‚úÖ Step 8: Compute Metrics
character_error = cer(ground_truths, predictions)
word_error = wer(ground_truths, predictions)

character_accuracy = 100 * (1 - character_error)
word_accuracy = 100 * (1 - word_error)

# ‚úÖ Step 9: Print Results
print("\nüìà Improved Evaluation Summary:")
print(f"üßÆ Character Error Rate (CER):   {character_error:.4f}")
print(f"‚úÖ Character-Level Accuracy:     {character_accuracy:.2f}%")
print(f"üßÆ Word Error Rate (WER):        {word_error:.4f}")
print(f"‚úÖ Word-Level Accuracy:          {word_accuracy:.2f}%")

"""# Prediction of Printed + Handwritten Text Image Using EasyOCR"""

!pip install easyocr
!pip install opencv-python matplotlib

import easyocr
import matplotlib.pyplot as plt
import cv2
from PIL import Image

# Load image
img_path = "/content/whatsapp.jpg"
image = cv2.imread(img_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Initialize OCR reader
reader = easyocr.Reader(['en'], gpu=False)  # CPU-only

# Perform OCR
results = reader.readtext(img_path)

# Show image with boxes
for (bbox, text, prob) in results:
    (top_left, top_right, bottom_right, bottom_left) = bbox
    top_left = tuple(map(int, top_left))
    bottom_right = tuple(map(int, bottom_right))
    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)
    cv2.putText(image, text, (top_left[0], top_left[1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

# Show image
plt.figure(figsize=(12, 12))
plt.imshow(image)
plt.axis('off')
plt.show()

# Print text
print("üìå Extracted Text:")
for (_, text, _) in results:
    print(text)

"""# Prediction of Printed + Handwritten Text Image Using Tesseract

"""

# STEP 1: Install Tesseract and pytesseract
!apt install tesseract-ocr
!apt install tesseract-ocr-hin
!pip install pytesseract
!pip install pillow

# STEP 2: Import Libraries
import pytesseract
from PIL import Image
import matplotlib.pyplot as plt

# STEP 3: Load Your Image
image_path = "/content/whatsapp.jpg"  # Replace with your image
img = Image.open(image_path)

# STEP 4: OCR Text Extraction (English + Hindi)
text = pytesseract.image_to_string(img, lang='eng+hin')
print("üìå Extracted Text:")
print(text)

# STEP 5: Display the Image
plt.imshow(img)
plt.axis('off')
plt.title("Input Image")
plt.show()

"""# Prediction of Printed + Handwritten Text Image Using TrOCR"""

from google.colab import files
uploaded = files.upload()  # Upload a full handwritten page image

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import torch

# Load model and processor
processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

import cv2
import numpy as np
from PIL import Image

# Load and preprocess image
img_path = list(uploaded.keys())[0]
image = cv2.imread(img_path)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Horizontal line projection to find line regions
horizontal_sum = np.sum(thresh, axis=1)
lines = []
start = None

for i, val in enumerate(horizontal_sum):
    if val > 0 and start is None:
        start = i
    elif val == 0 and start is not None:
        end = i
        if end - start > 15:  # filter short noise
            lines.append((start, end))
        start = None

from PIL import Image
results = []

for y1, y2 in lines:
    line_img = image[y1:y2, :]
    pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
    pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values

    # Beam decoding for accuracy
    generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
    predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    results.append(predicted_text)

print("üìù Final Predicted Text:")
for line in results:
    print(line)

"""# Prediction of all the Handwritten Paragraph Images using TrOCR"""

import zipfile
import os

zip_path = "/content/english_paragraph.zip"
extract_path = "/content/english_paragraph"

# Ensure clean extraction directory
if not os.path.exists(extract_path):
    os.makedirs(extract_path)

# Extract
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("‚úÖ Successfully unzipped to:", extract_path)

!pip install jiwer

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import torch

# Load model and processor
processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

import os
import glob
import cv2
import numpy as np
from PIL import Image
import torch
from tqdm import tqdm
from jiwer import cer, wer

# Define paths (using the extraction path from the unzip step)
image_dir = "/content/english_paragraph/english_paragraph"
gt_dir = os.path.join(image_dir, "ground_truth")

# Ensure model and processor are loaded and model is on the correct device
# Assuming 'model' and 'processor' are already loaded from a previous cell
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Preprocessing function (reusing the one from previous analysis)
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            if end - start > 15:  # filter short noise
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        lines.append((start, len(horizontal_sum)))

    return img, lines


# Prediction function for lines
def predict_text_from_lines(image, lines):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images

    return " ".join(predicted_lines).replace("  ", " ") # Join lines with space and clean up extra spaces


# Get all image paths (including .jpg and .png)
image_paths = sorted(glob.glob(os.path.join(image_dir, "*.png")) + glob.glob(os.path.join(image_dir, "*.jpg")))

if len(image_paths) == 0:
    print(f"No images found in the directory: {image_dir}")
else:
    predictions, ground_truths = [], []

    print(f"üìä Evaluating TrOCR Line-by-Line OCR on {len(image_paths)} images...\n")

    # Wrap image_paths with tqdm for a progress bar
    for image_path in tqdm(image_paths, desc="üîç Processing Images"):
        base_name = os.path.basename(image_path).replace(".png", ".txt").replace(".jpg", ".txt")
        gt_path = os.path.join(gt_dir, base_name)

        if not os.path.exists(gt_path):
            print(f"\n‚ö†Ô∏è Missing GT for {base_name}, skipping.")
            continue

        # Process image and get lines
        try:
            image, lines = preprocess_image_for_lines(image_path)
            # Predict text from detected lines
            pred_text = predict_text_from_lines(image, lines).lower()

            # Get ground truth text
            with open(gt_path, "r", encoding="utf-8") as f:
                gt_text = f.read().strip().lower()

            ground_truths.append(gt_text)
            predictions.append(pred_text)

        except Exception as e:
            print(f"\n‚ùå Error processing {os.path.basename(image_path)}: {e}")
            # Append empty strings to maintain list length for metrics calculation
            ground_truths.append("")
            predictions.append("")


    # Compute Metrics
    if len(ground_truths) > 0:
        character_error = cer(ground_truths, predictions)
        word_error = wer(ground_truths, predictions)

        character_accuracy = 100 * (1 - character_error)
        word_accuracy = 100 * (1 - word_error)

        # Print Results
        print("\nüìà Evaluation Summary:")
        print(f"üßÆ Character Error Rate (CER):   {character_error:.4f}")
        print(f"‚úÖ Character-Level Accuracy:     {character_accuracy:.2f}%")
        print(f"üßÆ Word Error Rate (WER):        {word_error:.4f}")
        print(f"‚úÖ Word-Level Accuracy:          {word_accuracy:.2f}%")
    else:
        print("\n‚ö†Ô∏è No images were processed for evaluation.")





# Add your code here and tell me what you want to achieve.

from google.colab import files
uploaded = files.upload()  # Upload a full handwritten¬†page¬†image

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import torch

# Load model and processor
processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

import cv2
import numpy as np
from PIL import Image

# Load and preprocess image
img_path = list(uploaded.keys())[0]
image = cv2.imread(img_path)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Horizontal line projection to find line regions
horizontal_sum = np.sum(thresh, axis=1)
lines = []
start = None

for i, val in enumerate(horizontal_sum):
    if val > 0 and start is None:
        start = i
    elif val == 0 and start is not None:
        end = i
        if end - start > 15:  # filter short noise
            lines.append((start, end))
        start = None

from PIL import Image
results = []

for y1, y2 in lines:
    line_img = image[y1:y2, :]
    pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
    pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values

    # Beam decoding for accuracy
    generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
    predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    results.append(predicted_text)

print("üìù Final Predicted Text:")
for line in results:
    print(line)

from google.colab import files
uploaded = files.upload()  # Upload a full handwritten¬†page¬†image

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import torch

# Load model and processor
processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

import cv2
import numpy as np
from PIL import Image

# Load and preprocess image
img_path = list(uploaded.keys())[0]
image = cv2.imread(img_path)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

# Horizontal line projection to find line regions
horizontal_sum = np.sum(thresh, axis=1)
lines = []
start = None

for i, val in enumerate(horizontal_sum):
    if val > 0 and start is None:
        start = i
    elif val == 0 and start is not None:
        end = i
        if end - start > 15:  # filter short noise
            lines.append((start, end))
        start = None

from PIL import Image
results = []

for y1, y2 in lines:
    line_img = image[y1:y2, :]
    pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
    pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values

    # Beam decoding for accuracy
    generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
    predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    results.append(predicted_text)

print("üìù Final Predicted Text:")
for line in results:
    print(line)



from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function (reusing the one from previous analysis)
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15:
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        lines.append((start, len(horizontal_sum)))

    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload the 4 images
print("Please upload the 4 images:")
uploaded_files = files.upload()

if len(uploaded_files) == 0:
    print("‚ùå No files uploaded.")
elif len(uploaded_files) != 4:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded_files)} files. Expected 4 images. Processing the uploaded files anyway.")


# Process each uploaded image
print("\n‚ñ∂Ô∏è Processing uploaded images...")
for filename in uploaded_files.keys():
    print(f"\n--- Processing: {filename} ---")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded_files[filename])

        image, lines = preprocess_image_for_lines(filename)
        if lines:
            predicted_text = predict_text_from_lines(image, lines)
            print(predicted_text)
        else:
            print("No lines detected in this image.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing uploaded images.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function (reusing the one from previous analysis)
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15:
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        lines.append((start, len(horizontal_sum)))

    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
try:
    # Save the uploaded file temporarily to process with OpenCV
    with open(filename, 'wb') as f:
        f.write(uploaded[filename])

    image, lines = preprocess_image_for_lines(filename)
    if lines:
        predicted_text = predict_text_from_lines(image, lines)
        print("\nüìù Predicted Text:")
        print(predicted_text)
    else:
        print("No lines detected in this image.")

    # Clean up the temporary file
    os.remove(filename)

except Exception as e:
    print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function (reusing the one from previous analysis)
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15:
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        lines.append((start, len(horizontal_sum)))

    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            pil_img = Image.fromarray(cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
try:
    # Save the uploaded file temporarily to process with OpenCV
    with open(filename, 'wb') as f:
        f.write(uploaded[filename])

    image, lines = preprocess_image_for_lines(filename)
    if lines:
        predicted_text = predict_text_from_lines(image, lines)
        print("\nüìù Predicted Text:")
        print(predicted_text)
    else:
        print("No lines detected in this image.")

    # Clean up the temporary file
    os.remove(filename)

except Exception as e:
    print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")







from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")

from google.colab import files
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import os

# Load model and processor (reusing if already loaded)
try:
    processor
    model
except NameError:
    print("Loading TrOCR model and processor...")
    processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
    model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
print("‚úÖ Model loaded and on device.")

# Preprocessing function to detect lines
def preprocess_image_for_lines(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Image not loaded: {image_path}")

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Using OTSU's thresholding
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Horizontal line projection to find line regions
    horizontal_sum = np.sum(thresh, axis=1)
    lines = []
    start = None

    for i, val in enumerate(horizontal_sum):
        if val > 0 and start is None:
            start = i
        elif val == 0 and start is not None:
            end = i
            # Filter short noise lines, adjust threshold (e.g., 15) if needed
            if end - start > 15: # You can adjust this threshold
                lines.append((start, end))
            start = None
    # Add the last line if the image doesn't end with a zero sum
    if start is not None:
        if len(horizontal_sum) - start > 15: # Check last segment length
             lines.append((start, len(horizontal_sum)))


    return img, lines

# Prediction function for lines
def predict_text_from_lines(image, lines, processor, model, device):
    predicted_lines = []
    for y1, y2 in lines:
        line_img = image[y1:y2, :]
        # Ensure the line image is valid before processing
        if line_img.shape[0] > 0 and line_img.shape[1] > 0:
            # Convert to grayscale and add a channel dimension
            gray_line_img = cv2.cvtColor(line_img, cv2.COLOR_BGR2GRAY)
            # Add a channel dimension to the grayscale image
            gray_line_img_3d = np.expand_dims(gray_line_img, axis=-1)
            # Convert to RGB format with 3 identical channels for the processor
            pil_img = Image.fromarray(cv2.cvtColor(gray_line_img_3d, cv2.COLOR_GRAY2RGB))
            try:
                pixel_values = processor(images=pil_img, return_tensors="pt").pixel_values.to(device)
                # Beam decoding for accuracy
                generated_ids = model.generate(pixel_values, max_length=128, num_beams=5, early_stopping=True)
                predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                predicted_lines.append(predicted_text.strip())
            except Exception as e:
                predicted_lines.append(f"[OCR ERROR] {e}")
        else:
            predicted_lines.append("") # Append empty string for invalid line images


    return "\n".join(predicted_lines) # Join lines with newline for better readability

# Upload a single image
print("Please upload a single image:")
uploaded = files.upload()

if len(uploaded) == 0:
    print("‚ùå No file uploaded.")
elif len(uploaded) > 1:
     print(f"‚ö†Ô∏è You uploaded {len(uploaded)} files. Expected 1 image. Processing the first uploaded file.")
     filename = list(uploaded.keys())[0]
else:
    filename = list(uploaded.keys())[0]


# Process the uploaded image
if filename:
    print(f"\n‚ñ∂Ô∏è Processing: {filename}...")
    try:
        # Save the uploaded file temporarily to process with OpenCV
        with open(filename, 'wb') as f:
            f.write(uploaded[filename])

        image, lines = preprocess_image_for_lines(filename)
        print(f"‚úÖ Detected {len(lines)} lines.")
        if lines:
            # Pass model and processor to the prediction function
            predicted_text = predict_text_from_lines(image, lines, processor, model, device)
            print("\nüìù Predicted Text:")
            print(predicted_text)
        else:
            print("No lines detected in this image that meet the size threshold.")

        # Clean up the temporary file
        os.remove(filename)

    except Exception as e:
        print(f"‚ùå Error processing {filename}: {e}")

print("\n‚úÖ Finished processing the image.")